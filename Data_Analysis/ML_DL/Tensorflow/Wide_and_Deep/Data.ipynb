{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99e68d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdb0b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.utils = Utils()\n",
    "\n",
    "    def get_wide_model_data(self, df_train, df_test):\n",
    "\n",
    "        df_train['IS_TRAIN'] = 1\n",
    "        df_test['IS_TRAIN'] = 0\n",
    "        df_wide = pd.concat([df_train, df_test])\n",
    "\n",
    "        wide_cols = ['workclass', 'education', 'marital_status', 'occupation',\n",
    "                     'relationship', 'race', 'gender', 'native_country', 'age_group']\n",
    "        crossed_cols = (['education', 'occupation'], ['native_country', 'occupation'])\n",
    "        target = 'income_label'\n",
    "        categorical_columns = list(df_wide.select_dtypes(include=['object']).columns)\n",
    "\n",
    "        crossed_columns_dic = self.utils.cross_columns(crossed_cols)\n",
    "        wide_cols += list(crossed_columns_dic.keys())\n",
    "\n",
    "        # crossed 변수 추가\n",
    "        for col_name, col_lst in crossed_columns_dic.items():\n",
    "            df_wide[col_name] = df_wide[col_lst].apply(lambda x: '-'.join(x), axis=1)\n",
    "        df_wide = df_wide[wide_cols + [target] + ['IS_TRAIN']]\n",
    "\n",
    "        # dummy로 변경\n",
    "        dummy_cols = [wc for wc in wide_cols if wc in categorical_columns + list(crossed_columns_dic.keys())]\n",
    "        df_wide = pd.get_dummies(df_wide, columns=dummy_cols)\n",
    "\n",
    "        train = df_wide[df_wide.IS_TRAIN == 1].drop('IS_TRAIN', axis=1)\n",
    "        test = df_wide[df_wide.IS_TRAIN == 0].drop('IS_TRAIN', axis=1)\n",
    "\n",
    "        cols = [c for c in train.columns if c != target]\n",
    "        X_train = train[cols].values\n",
    "        X_train = np.array(X_train, dtype=np.float)\n",
    "        y_train = train[target].values.reshape(-1, 1)\n",
    "\n",
    "        X_test = test[cols].values\n",
    "        X_test = np.array(X_test, dtype=np.float)\n",
    "        y_test = test[target].values.reshape(-1, 1)\n",
    "\n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "    def get_deep_model_data(self, df_train, df_test):\n",
    "\n",
    "        df_train['IS_TRAIN'] = 1\n",
    "        df_test['IS_TRAIN'] = 0\n",
    "        df_deep = pd.concat([df_train, df_test])\n",
    "\n",
    "        embedding_cols = ['workclass', 'education', 'marital_status', 'occupation',\n",
    "                          'relationship', 'race', 'gender', 'native_country']\n",
    "        cont_cols = ['age', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "        target = 'income_label'\n",
    "\n",
    "        deep_cols = embedding_cols + cont_cols\n",
    "        df_deep = df_deep[deep_cols + [target, 'IS_TRAIN']]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        df_deep[cont_cols] = pd.DataFrame(scaler.fit_transform(df_train[cont_cols]), columns=cont_cols)\n",
    "        df_deep, col_to_unique_val_num = self.utils.val2idx(df_deep, embedding_cols)\n",
    "\n",
    "        train = df_deep[df_deep.IS_TRAIN == 1].drop('IS_TRAIN', axis=1)\n",
    "        test = df_deep[df_deep.IS_TRAIN == 0].drop('IS_TRAIN', axis=1)\n",
    "\n",
    "        embeddings_tensors = []\n",
    "        for ec in embedding_cols:\n",
    "            layer_name = ec + '_inp'\n",
    "            inp = Input(shape=(1,), dtype='int64', name=layer_name)\n",
    "            embd = Embedding(col_to_unique_val_num[ec], 8, input_length=1, embeddings_regularizer=l2(1e-3))(inp)\n",
    "            embeddings_tensors.append((inp, embd))\n",
    "            del (inp, embd)\n",
    "\n",
    "        continuous_tensors = []\n",
    "        for cc in cont_cols:\n",
    "            layer_name = cc + '_in'\n",
    "            inp = Input(shape=(1,), dtype='float32', name=layer_name)\n",
    "            bulid = Reshape((1, 1))(inp)\n",
    "            continuous_tensors.append((inp, bulid))\n",
    "            del (inp, bulid)\n",
    "\n",
    "        X_train = [train[c] for c in deep_cols]\n",
    "        y_train = np.array(train[target].values).reshape(-1, 1)\n",
    "\n",
    "        X_test = [test[c] for c in deep_cols]\n",
    "        y_test = np.array(test[target].values).reshape(-1, 1)\n",
    "\n",
    "        return X_train, y_train, X_test, y_test, embeddings_tensors, continuous_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047f9028",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "\n",
    "    def cross_columns(self, x_cols):\n",
    "\n",
    "        crossed_columns = dict()\n",
    "        colnames = ['_'.join(x_c) for x_c in x_cols]\n",
    "        for cname, x_c in zip(colnames, x_cols):\n",
    "            crossed_columns[cname] = x_c\n",
    "        return crossed_columns\n",
    "\n",
    "    def val2idx(self, df, cols):\n",
    "\n",
    "        val_types = dict()\n",
    "        for c in cols:\n",
    "            val_types[c] = df[c].unique()\n",
    "\n",
    "        val_to_idx = dict()\n",
    "        for k, v in val_types.items():\n",
    "            val_to_idx[k] = {o: i for i, o in enumerate(val_types[k])}\n",
    "\n",
    "        for k, v in val_to_idx.items():\n",
    "            df[k] = df[k].apply(lambda x: v[x])\n",
    "\n",
    "        unique_vals = dict()  # 사용한 값만\n",
    "        for c in cols:\n",
    "            unique_vals[c] = df[c].nunique()\n",
    "\n",
    "        return df, unique_vals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Study)",
   "language": "python",
   "name": "pycharm-2419e99e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
