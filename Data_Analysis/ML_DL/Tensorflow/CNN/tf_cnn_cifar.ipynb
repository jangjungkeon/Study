{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "tf_cnn_cifar10.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "name": "pycharm-2419e99e",
   "language": "python",
   "display_name": "PyCharm (Study)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "Kiedta2qG70d"
   },
   "source": [
    "# CIFAR-10 : 10개의 레이블, 6만장의 칼라 이미지(5만장 - train, 1만장 - test)\n",
    "# airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "# DENSE 레이어로만 분류작업1\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ghff9DKSIhr2"
   },
   "source": [
    "NUM_CLASSES = 10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('train data')\n",
    "print(x_train.shape)        #(50000, 32, 32, 3)\n",
    "print(x_train.shape[0])\n",
    "print(x_train.shape[3])     # 채널\n",
    "print('test data')\n",
    "print(x_test.shape)         # (10000, 32, 32, 3)\n",
    "\n",
    "# print(x_train[0])\n",
    "# print(y_train[0])     # frog\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(x_train[0], interpolation='bicubic')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(x_train[1], interpolation='bicubic')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(x_train[2], interpolation='bicubic')\n",
    "\n",
    "x_train = x_train.astype('float32')  / 255.0\n",
    "x_test = x_test.astype('float32')  / 255.0\n",
    "\n",
    "y_train = to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "# print(x_train)\n",
    "print(x_train[54,12,13,1])      # 0.36862746.  54번째 인덱스(이미지)의 12행 13열 중에 1번채널(초록색), 2번은 파란색 "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F4Ii_eJ9MBc5"
   },
   "source": [
    "# 방법1 : Sequential API를 사용 (CNN)\n",
    "model = Sequential([\n",
    "                    Dense(512, input_shape=(32, 32, 3), activation='relu'),\n",
    "                    Flatten(),\n",
    "                    Dense(128, activation='relu'),\n",
    "                    Dense(NUM_CLASSES, activation='softmax'),\n",
    "])\n",
    "\n",
    "print(model.summary())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i7kiZk53M97Y"
   },
   "source": [
    "# 방법2 : Function API를 사용 (CNN x)\n",
    "input_layer = Input((32, 32, 3))\n",
    "x = Flatten()(input_layer)      # Input(shape=(32, 32, 3))\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output_layer = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "print(model.summary())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_2NXBVWQOCN4"
   },
   "source": [
    "# train\n",
    "opt = Adam(lr = 0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=10, shuffle=True, verbose=2)\n",
    "print('acc:%.4f' %(model.evaluate(x_test, y_test, batch_size=128)[1]))\n",
    "print('loss:%.4f' %(model.evaluate(x_test, y_test, batch_size=128)[0]))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N0gwHKMlPMLq"
   },
   "source": [
    "CLASSES = np.array([\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"])\n",
    "\n",
    "pred = model.predict(x_test[:10])\n",
    "pred_single = CLASSES[np.argmax(pred, axis=-1)]\n",
    "actual_single = CLASSES[np.argmax(y_test[:10], axis=-1)]\n",
    "print('예측값 : ', pred_single)\n",
    "print('실제값 : ', actual_single)\n",
    "print('분류 실패 수 : ', (pred_single != actual_single).sum())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "znFofyvuVdOv"
   },
   "source": [
    "# 시각화\n",
    "fig = plt.figure(figsize= (15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, idx in enumerate(range(len(x_test[:10]))):\n",
    "  img = x_test[idx]\n",
    "  ax = fig.add_subplot(1, len(x_test[:10]), i + 1)\n",
    "  ax.axis('off')\n",
    "  ax.text(0.5, -0.35, 'pred  =  ' + str(pred_single[idx]), fontsize=10,  ha = 'center', transform = ax.transAxes)\n",
    "  ax.text(0.5, -0.7, 'act  =  ' + str(actual_single[idx]), fontsize=10,  ha = 'center', transform = ax.transAxes)\n",
    "  ax.imshow(img)\n",
    "\n",
    "plt.show()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zw4oV1gpW9jB"
   },
   "source": [
    "# CNN + Dense 레이어로만 분류작업\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, Activation, BatchNormalization, ReLU, LeakyReLU, MaxPool2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UGmK7uYZXCyF"
   },
   "source": [
    "NUM_CLASSES = 10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')  / 255.0\n",
    "x_test = x_test.astype('float32')  / 255.0\n",
    "\n",
    "y_train = to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, NUM_CLASSES)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "w6d3B-rLYE3p"
   },
   "source": [
    "# function API, CNN + Dense\n",
    "input_layer = Input(shape=(32, 32, 3))\n",
    "conv_layer1 = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(input_layer)\n",
    "conv_layer2 = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(conv_layer1)\n",
    "\n",
    "flatten_layer = Flatten()(conv_layer2)\n",
    "\n",
    "output_layer = Dense(units = 10, activation='softmax')(flatten_layer)\n",
    "model = Model(input_layer, output_layer)\n",
    "print(model.summary())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cC3PgbBoaXE4"
   },
   "source": [
    "# function API, CNN + Dense\n",
    "input_layer = Input(shape=(32, 32, 3))\n",
    "x = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(input_layer)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(512)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Dense(128)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Dense(NUM_CLASSES)(x)\n",
    "output_layer = Activation('softmax')(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jaHL6OlNZx77"
   },
   "source": [
    "# train\n",
    "opt = Adam(lr = 0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=10, shuffle=True, verbose=2)\n",
    "print('acc:%.4f' %(model.evaluate(x_test, y_test, batch_size=128)[1]))\n",
    "print('loss:%.4f' %(model.evaluate(x_test, y_test, batch_size=128)[0]))"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}