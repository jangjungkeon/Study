{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "tf_cnn_mnist_subclassing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "pycharm-2419e99e",
   "language": "python",
   "display_name": "PyCharm (Study)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "knLexc4SEuG3",
    "outputId": "cc2e0e61-1476-4f0a-9e64-62310c569fc8"
   },
   "source": [
    "# MNIST 로 CNN 연습\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, models, layers, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "print(train_images.shape)\n",
    "\n",
    "# CNN : 3차원을 4차원으로 구조 변경(채널 추가)\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "print(train_images.shape, train_images.ndim)\n",
    "train_images = train_images / 255.0\n",
    "# print(train_images[0])\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images / 255.0\n",
    "print(train_labels[:3])"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "(60000, 28, 28)\n",
      "(60000, 28, 28, 1) 4\n",
      "[5 0 4]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DFsmwDptFnZX",
    "outputId": "bc1a1339-d33d-4e57-8972-e12aaca4e8d3"
   },
   "source": [
    "# 데이터 섞기\n",
    "import numpy as np\n",
    "x = np.random.sample((5, 2))\n",
    "print(x)\n",
    "dset = tf.data.Dataset.from_tensor_slices(x)\n",
    "print(dset)\n",
    "# 버퍼의 크기는 여유있게 크게 주는게 좋다. 데이터 갯수보다 많이 하는게 좋음. \n",
    "dset = tf.data.Dataset.from_tensor_slices(x).shuffle(100).batch(2)    # batch(2) 묶음 수\n",
    "print(dset)\n",
    "for a in dset:\n",
    "  print(a)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[[0.55934871 0.76513513]\n",
      " [0.34117896 0.52255886]\n",
      " [0.98673724 0.6138614 ]\n",
      " [0.50428399 0.54350374]\n",
      " [0.11727763 0.24743795]]\n",
      "<TensorSliceDataset shapes: (2,), types: tf.float64>\n",
      "<BatchDataset shapes: (None, 2), types: tf.float64>\n",
      "tf.Tensor(\n",
      "[[0.11727763 0.24743795]\n",
      " [0.34117896 0.52255886]], shape=(2, 2), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[0.50428399 0.54350374]\n",
      " [0.98673724 0.6138614 ]], shape=(2, 2), dtype=float64)\n",
      "tf.Tensor([[0.55934871 0.76513513]], shape=(1, 2), dtype=float64)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvpwT-DvICN8",
    "outputId": "4628af7b-2b65-4767-b7e3-400ae084a767"
   },
   "source": [
    "# MNIST의 train data 섞기\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(60000).batch(28)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(28)\n",
    "print(train_ds)\n",
    "print(test_ds)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float64, tf.uint8)>\n",
      "<BatchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float64, tf.uint8)>\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kRYF9lvLI1SD",
    "outputId": "c3caeef5-2c91-4e6c-d21b-d3d4f2cbb4a5"
   },
   "source": [
    "# 모델 생성방법 - subclassing API\n",
    "class MyModel(Model):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.conv1 = Conv2D(filters=32, kernel_size=[3, 3], padding='valid', activation='relu')\n",
    "    self.pool1 = MaxPool2D((2, 2))\n",
    "\n",
    "    self.conv2 = Conv2D(filters=32, kernel_size=[3, 3], padding='valid', activation='relu')\n",
    "    self.pool2 = MaxPool2D((2, 2))\n",
    "\n",
    "    self.flatten = Flatten(dtype='float32')\n",
    "\n",
    "    self.d1 = Dense(64, activation='relu')\n",
    "    self.drop1 = Dropout(rate=0.3)\n",
    "    self.d2 = Dense(10, activation='softmax')\n",
    "  \n",
    "  # call 이 init의 내용을 사용함\n",
    "  def call(self, inputs):\n",
    "    net = self.conv1(inputs)\n",
    "    net = self.pool1(net)\n",
    "    net = self.conv2(net)\n",
    "    net = self.pool2(net)\n",
    "    net = self.flatten(net)\n",
    "    net = self.d1(net)\n",
    "    net = self.drop1(net)\n",
    "    net = self.d2(net)\n",
    "    return net\n",
    "\n",
    "model = MyModel()\n",
    "tmp_inputs = tf.keras.Input(shape = (28, 28, 1))\n",
    "model(tmp_inputs)\n",
    "print(model.summary())"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"my_model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            multiple                  320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            multiple                  9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  51264     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  650       \n",
      "=================================================================\n",
      "Total params: 61,482\n",
      "Trainable params: 61,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GTimcQGFJNrn",
    "outputId": "42aae232-70d4-47be-c35d-a668a46964fc"
   },
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# 일반적인 모델 학습 방법1\n",
    "model.compile(optimizer=optimizer, loss=loss_object, metrics=['acc'])\n",
    "model.fit(train_images, train_labels, batch_size=128, epochs=5, verbose=2, max_queue_size=10, workers=1, use_multiprocessing=True)\n",
    "score = model.evaluate(test_images, test_labels)\n",
    "print('test loss : ', score[0])\n",
    "print('test acc : ', score[1])\n",
    "\n",
    "import numpy as np\n",
    "print('예측 값 : ', np.argmax(model.predict(test_images[:2]), 1))\n",
    "print('실제 값 : ', test_labels[:2])"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 - 34s - loss: 0.3596 - acc: 0.8901\n",
      "Epoch 2/5\n",
      "469/469 - 1s - loss: 0.1083 - acc: 0.9672\n",
      "Epoch 3/5\n",
      "469/469 - 1s - loss: 0.0804 - acc: 0.9754\n",
      "Epoch 4/5\n",
      "469/469 - 1s - loss: 0.0671 - acc: 0.9797\n",
      "Epoch 5/5\n",
      "469/469 - 1s - loss: 0.0541 - acc: 0.9832\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0362 - acc: 0.9886\n",
      "test loss :  0.036177534610033035\n",
      "test acc :  0.9886000156402588\n",
      "예측 값 :  [7 2]\n",
      "실제 값 :  [7 2]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PAXt6A6VSR3C",
    "outputId": "3903fe69-adaa-4bd1-a744-62b4bbdbebba"
   },
   "source": [
    "# 모델 학습 방법 2 : GradientTape 사용\n",
    "train_loss = tf.keras.metrics.Mean()\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean()\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(images)\n",
    "    loss = loss_object(labels, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "  train_loss(loss)      # 가중치 평균 계산\n",
    "  train_accuracy(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "  for train_images, train_labels in train_ds:\n",
    "    train_step(train_images, train_labels)\n",
    "  \n",
    "  for test_images, test_labels in test_ds:\n",
    "    test_step(test_images, test_labels)\n",
    "  \n",
    "  template = 'epochs: {}, train_loss:{}, train_acc:{}, test_loss:{}, test_acc:{}'\n",
    "  print(template.format(epoch + 1, train_loss.result(), train_accuracy.result()*100, \n",
    "                        test_loss.result(), test_accuracy.result()*100))\n",
    "  \n",
    "print('예측 값 : ', np.argmax(model.predict(test_images[:2]), 1))\n",
    "print('실제 값 : ', test_labels[:2].numpy())"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "epochs: 1, train_loss:0.010421371087431908, train_acc:99.63999938964844, test_loss:0.04149317368865013, test_acc:98.95999908447266\n",
      "epochs: 2, train_loss:0.0099940225481987, train_acc:99.65499877929688, test_loss:0.03994537144899368, test_acc:99.01000213623047\n",
      "epochs: 3, train_loss:0.009059558622539043, train_acc:99.69000244140625, test_loss:0.03963252529501915, test_acc:99.03666687011719\n",
      "epochs: 4, train_loss:0.008747817948460579, train_acc:99.70249938964844, test_loss:0.03996562957763672, test_acc:99.05750274658203\n",
      "epochs: 5, train_loss:0.008145938627421856, train_acc:99.72166442871094, test_loss:0.04254552349448204, test_acc:99.01200103759766\n",
      "예측 값 :  [3 4]\n",
      "실제 값 :  [3 4]\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}