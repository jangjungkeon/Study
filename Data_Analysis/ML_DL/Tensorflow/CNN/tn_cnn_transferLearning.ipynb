{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transfer Learning (전이학습) : 미리 학습된 모델을 사용하여 내가 분류하고자 하는 데이터를 이용해\n",
    "\n",
    "# ! pip install tensorflow-datasets\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tfds dataset : 텐서플로(구글)에서 제공하는 데이터셋, cats_vs_dogs\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "# train : validation : test = 8 : 1 : 1\n",
    "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
    "    'cats_vs_dogs', split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'], with_info=True, as_supervised=True)\n",
    "\n",
    "print(raw_train)\n",
    "print(raw_validation)\n",
    "print(raw_test)\n",
    "print(metadata)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_label_name = metadata.features['label'].int2str\n",
    "print(get_label_name)\n",
    "for image, label in raw_train.take(5):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.title(get_label_name(label))\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "IMG_SIZE = 160   # All images will be resized to 160 by160\n",
    "\n",
    "def format_example(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/127.5) - 1\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    return image, label\n",
    "\n",
    "train = raw_train.map(format_example)\n",
    "validation = raw_validation.map(format_example)\n",
    "test = raw_test.map(format_example)\n",
    "\n",
    "# 4. 이미지 셔플링 배칭\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "\n",
    "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "validation_batches = validation.batch(BATCH_SIZE)\n",
    "test_batches = test.batch(BATCH_SIZE)\n",
    "# 학습 데이터는 임의로 셔플하고 배치 크기를 정하여 배치로 나누어준다.\n",
    "\n",
    "for image_batch, label_batch in train_batches.take(1):\n",
    "    pass\n",
    "\n",
    "print(image_batch.shape)    # [32, 160, 160, 3]\n",
    "print(label_batch.shape)    # [32,]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5. 베이스 모델 생성 : 전이학습에서 사용할 베이스 모델은 Google에서 개발한 MobileNet V2 모델 사용.\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)   # (32, 5, 5, 1280)\n",
    "\n",
    "# include_top=False 입력층 -> cnn 계층 -> 특징 추출 -> 완전 연결층"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 계층 동결\n",
    "base_model.trainable = False  # MobileNetV2 학습 정지\n",
    "print(base_model.summary())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 전이 학습을 위한 모델을 생성\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()   # 급격히 feature의 수를 줄여주는 역할\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average)    # (32, 1280)\n",
    "\n",
    "prediction_layer = tf.keras.layers.Dense(1)\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)   # (32, 1)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                             base_model,\n",
    "                             global_average_layer,\n",
    "                             prediction_layer\n",
    "\n",
    "])\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 현재 모델 확인\n",
    "validation_steps = 20\n",
    "print(validation_batches)\n",
    "loss0, accuracy0 = model.evaluate(validation_batches, steps=validation_steps)\n",
    "print('initial loss : {:.2}'.format(loss0))\n",
    "print('initial acc : {:.2}'.format(accuracy0))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "initial_epochs = 5      # 원래는 10 이상 줘야됨.\n",
    "history = model.fit(train_batches, epochs=initial_epochs, validation_data=validation_batches)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 학습 시각화\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training accuracy')\n",
    "plt.plot(val_acc, label='Validation accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()), 1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training loss')\n",
    "plt.plot(val_loss, label='Validation loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross entropy')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epochs')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 전이 학습 파인 튜닝 : 미리 학습 된 ConvNet의 마지막 FC Layer만 변경해 분류 실행\n",
    "# 이전 학습의 모바일넷을 동결시키고 새로 추가한 레이어만 학습 (베이스 모델의 후방 레이어 일부만 다시 학습)\n",
    "# 먼저 베이스 모델을 동결한 후 학습 진행 -> 학습이 끝나면 동결 해제\n",
    "base_model.trainable = True\n",
    "print('베이스 모델의 레이어 : ', len(base_model.layers))    # 154\n",
    "\n",
    "fine_tune_at = 100\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_at]:      # 54개로만 학습\n",
    "  layer.trainable = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate / 10), metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# fine tune 학습\n",
    "fine_tune_epochs = 2    # 10이상 줘야됨\n",
    "# initial_epochs = 2    # 10\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "history_fine = model.fit(train_batches, epochs = total_epochs, initial_epoch=history.epoch[-1],\n",
    "                         validation_data=validation_batches)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# 시각화\n",
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training accuracy')\n",
    "plt.plot(val_acc, label='Validation accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([initial_epochs - 1, initial_epochs - 1], plt.ylim(), label='Start fine tuning')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.8, 1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training loss')\n",
    "plt.plot(val_loss, label='Validation loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross entropy')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.plot([initial_epochs - 1, initial_epochs - 1], plt.ylim(), label='Start fine tuning')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epochs')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-2419e99e",
   "language": "python",
   "display_name": "PyCharm (Study)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}